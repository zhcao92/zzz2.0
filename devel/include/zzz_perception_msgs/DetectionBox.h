// Generated by gencpp from file zzz_perception_msgs/DetectionBox.msg
// DO NOT EDIT!


#ifndef ZZZ_PERCEPTION_MSGS_MESSAGE_DETECTIONBOX_H
#define ZZZ_PERCEPTION_MSGS_MESSAGE_DETECTIONBOX_H


#include <string>
#include <vector>
#include <map>

#include <ros/types.h>
#include <ros/serialization.h>
#include <ros/builtin_message_traits.h>
#include <ros/message_operations.h>

#include <sensor_msgs/PointCloud2.h>
#include <sensor_msgs/Image.h>
#include <zzz_perception_msgs/ObjectClass.h>
#include <zzz_perception_msgs/ObjectSignals.h>
#include <zzz_perception_msgs/BoundingBox.h>

namespace zzz_perception_msgs
{
template <class ContainerAllocator>
struct DetectionBox_
{
  typedef DetectionBox_<ContainerAllocator> Type;

  DetectionBox_()
    : source_cloud()
    , source_img()
    , source_frame()
    , classes()
    , signal()
    , bbox()
    , comments()  {
    }
  DetectionBox_(const ContainerAllocator& _alloc)
    : source_cloud(_alloc)
    , source_img(_alloc)
    , source_frame(_alloc)
    , classes(_alloc)
    , signal(_alloc)
    , bbox(_alloc)
    , comments(_alloc)  {
  (void)_alloc;
    }



   typedef  ::sensor_msgs::PointCloud2_<ContainerAllocator>  _source_cloud_type;
  _source_cloud_type source_cloud;

   typedef  ::sensor_msgs::Image_<ContainerAllocator>  _source_img_type;
  _source_img_type source_img;

   typedef std::basic_string<char, std::char_traits<char>, typename ContainerAllocator::template rebind<char>::other >  _source_frame_type;
  _source_frame_type source_frame;

   typedef std::vector< ::zzz_perception_msgs::ObjectClass_<ContainerAllocator> , typename ContainerAllocator::template rebind< ::zzz_perception_msgs::ObjectClass_<ContainerAllocator> >::other >  _classes_type;
  _classes_type classes;

   typedef  ::zzz_perception_msgs::ObjectSignals_<ContainerAllocator>  _signal_type;
  _signal_type signal;

   typedef  ::zzz_perception_msgs::BoundingBox_<ContainerAllocator>  _bbox_type;
  _bbox_type bbox;

   typedef std::basic_string<char, std::char_traits<char>, typename ContainerAllocator::template rebind<char>::other >  _comments_type;
  _comments_type comments;





  typedef boost::shared_ptr< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> > Ptr;
  typedef boost::shared_ptr< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> const> ConstPtr;

}; // struct DetectionBox_

typedef ::zzz_perception_msgs::DetectionBox_<std::allocator<void> > DetectionBox;

typedef boost::shared_ptr< ::zzz_perception_msgs::DetectionBox > DetectionBoxPtr;
typedef boost::shared_ptr< ::zzz_perception_msgs::DetectionBox const> DetectionBoxConstPtr;

// constants requiring out of line definition



template<typename ContainerAllocator>
std::ostream& operator<<(std::ostream& s, const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> & v)
{
ros::message_operations::Printer< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >::stream(s, "", v);
return s;
}


template<typename ContainerAllocator1, typename ContainerAllocator2>
bool operator==(const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator1> & lhs, const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator2> & rhs)
{
  return lhs.source_cloud == rhs.source_cloud &&
    lhs.source_img == rhs.source_img &&
    lhs.source_frame == rhs.source_frame &&
    lhs.classes == rhs.classes &&
    lhs.signal == rhs.signal &&
    lhs.bbox == rhs.bbox &&
    lhs.comments == rhs.comments;
}

template<typename ContainerAllocator1, typename ContainerAllocator2>
bool operator!=(const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator1> & lhs, const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator2> & rhs)
{
  return !(lhs == rhs);
}


} // namespace zzz_perception_msgs

namespace ros
{
namespace message_traits
{





template <class ContainerAllocator>
struct IsFixedSize< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
  : FalseType
  { };

template <class ContainerAllocator>
struct IsFixedSize< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> const>
  : FalseType
  { };

template <class ContainerAllocator>
struct IsMessage< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
  : TrueType
  { };

template <class ContainerAllocator>
struct IsMessage< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> const>
  : TrueType
  { };

template <class ContainerAllocator>
struct HasHeader< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
  : FalseType
  { };

template <class ContainerAllocator>
struct HasHeader< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> const>
  : FalseType
  { };


template<class ContainerAllocator>
struct MD5Sum< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
{
  static const char* value()
  {
    return "0a13bac53d8ff42860cb5814e580ec83";
  }

  static const char* value(const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator>&) { return value(); }
  static const uint64_t static_value1 = 0x0a13bac53d8ff428ULL;
  static const uint64_t static_value2 = 0x60cb5814e580ec83ULL;
};

template<class ContainerAllocator>
struct DataType< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
{
  static const char* value()
  {
    return "zzz_perception_msgs/DetectionBox";
  }

  static const char* value(const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator>&) { return value(); }
};

template<class ContainerAllocator>
struct Definition< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
{
  static const char* value()
  {
    return "# Defines a box-shaped 3D detection result.\n"
"\n"
"# ----------------- Data -----------------\n"
"\n"
"# The 3D data that generated these results (i.e. object region cropped out of\n"
"#   the point cloud). This information is not required for all detectors, so it may be empty.\n"
"sensor_msgs/PointCloud2 source_cloud\n"
"\n"
"# The 2D data in the same area for fusion purpose\n"
"sensor_msgs/Image source_img\n"
"\n"
"# The frame id of source_img\n"
"string source_frame\n"
"\n"
"# ---------------- Properties --------------------\n"
"\n"
"# Describe several classification result for the object\n"
"# This field is required to be sorted in descending order of scores\n"
"ObjectClass[] classes\n"
"\n"
"# This field indicates visual (or sound?) signal from the object\n"
"ObjectSignals signal\n"
"\n"
"# 3D bounding box surrounding the object.\n"
"BoundingBox bbox\n"
"\n"
"# This field is for store auxiliary text or data. (e.g. annotation notes)\n"
"string comments\n"
"\n"
"================================================================================\n"
"MSG: sensor_msgs/PointCloud2\n"
"# This message holds a collection of N-dimensional points, which may\n"
"# contain additional information such as normals, intensity, etc. The\n"
"# point data is stored as a binary blob, its layout described by the\n"
"# contents of the \"fields\" array.\n"
"\n"
"# The point cloud data may be organized 2d (image-like) or 1d\n"
"# (unordered). Point clouds organized as 2d images may be produced by\n"
"# camera depth sensors such as stereo or time-of-flight.\n"
"\n"
"# Time of sensor data acquisition, and the coordinate frame ID (for 3d\n"
"# points).\n"
"Header header\n"
"\n"
"# 2D structure of the point cloud. If the cloud is unordered, height is\n"
"# 1 and width is the length of the point cloud.\n"
"uint32 height\n"
"uint32 width\n"
"\n"
"# Describes the channels and their layout in the binary data blob.\n"
"PointField[] fields\n"
"\n"
"bool    is_bigendian # Is this data bigendian?\n"
"uint32  point_step   # Length of a point in bytes\n"
"uint32  row_step     # Length of a row in bytes\n"
"uint8[] data         # Actual point data, size is (row_step*height)\n"
"\n"
"bool is_dense        # True if there are no invalid points\n"
"\n"
"================================================================================\n"
"MSG: std_msgs/Header\n"
"# Standard metadata for higher-level stamped data types.\n"
"# This is generally used to communicate timestamped data \n"
"# in a particular coordinate frame.\n"
"# \n"
"# sequence ID: consecutively increasing ID \n"
"uint32 seq\n"
"#Two-integer timestamp that is expressed as:\n"
"# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n"
"# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n"
"# time-handling sugar is provided by the client library\n"
"time stamp\n"
"#Frame this data is associated with\n"
"string frame_id\n"
"\n"
"================================================================================\n"
"MSG: sensor_msgs/PointField\n"
"# This message holds the description of one point entry in the\n"
"# PointCloud2 message format.\n"
"uint8 INT8    = 1\n"
"uint8 UINT8   = 2\n"
"uint8 INT16   = 3\n"
"uint8 UINT16  = 4\n"
"uint8 INT32   = 5\n"
"uint8 UINT32  = 6\n"
"uint8 FLOAT32 = 7\n"
"uint8 FLOAT64 = 8\n"
"\n"
"string name      # Name of field\n"
"uint32 offset    # Offset from start of point struct\n"
"uint8  datatype  # Datatype enumeration, see above\n"
"uint32 count     # How many elements in the field\n"
"\n"
"================================================================================\n"
"MSG: sensor_msgs/Image\n"
"# This message contains an uncompressed image\n"
"# (0, 0) is at top-left corner of image\n"
"#\n"
"\n"
"Header header        # Header timestamp should be acquisition time of image\n"
"                     # Header frame_id should be optical frame of camera\n"
"                     # origin of frame should be optical center of camera\n"
"                     # +x should point to the right in the image\n"
"                     # +y should point down in the image\n"
"                     # +z should point into to plane of the image\n"
"                     # If the frame_id here and the frame_id of the CameraInfo\n"
"                     # message associated with the image conflict\n"
"                     # the behavior is undefined\n"
"\n"
"uint32 height         # image height, that is, number of rows\n"
"uint32 width          # image width, that is, number of columns\n"
"\n"
"# The legal values for encoding are in file src/image_encodings.cpp\n"
"# If you want to standardize a new string format, join\n"
"# ros-users@lists.sourceforge.net and send an email proposing a new encoding.\n"
"\n"
"string encoding       # Encoding of pixels -- channel meaning, ordering, size\n"
"                      # taken from the list of strings in include/sensor_msgs/image_encodings.h\n"
"\n"
"uint8 is_bigendian    # is this data bigendian?\n"
"uint32 step           # Full row length in bytes\n"
"uint8[] data          # actual matrix data, size is (step * rows)\n"
"\n"
"================================================================================\n"
"MSG: zzz_perception_msgs/ObjectClass\n"
"# The size of (in meters) the bounding box surrounding the object's center pose.\n"
"\n"
"# The unique numeric classification ID of object detected\n"
"uint32 classid\n"
"\n"
"# The probability or confidence value of the detected object. By convention, this value should lie in the range 0~1.\n"
"float32 score\n"
"\n"
"# Other information about the class (e.g. class name). Only for debug\n"
"string comments\n"
"\n"
"##############################################################\n"
"###   Here is a hierarchical table of all included types   ###\n"
"##############################################################\n"
"# Hierarchy is encoded in a 32-bit integer. Each 8 bit stand for a level, and leftmost 8 bit is the top level\n"
"\n"
"uint32 UNKNOWN                          = 0     # 0x0000\n"
"uint32 UNKNOWN_DYNAMIC                  = 16    # 0x0010\n"
"uint32 UNKNOWN_STATIC                   = 32    # 0x0020\n"
"\n"
"uint32 VEHICLE                          = 1     # 0x0001\n"
"uint32 VEHICLE_PASSENGER                = 17    # 0x0011, normal passenger_vehicles\n"
"uint32 VEHICEL_VAN                      = 33    # 0x0021\n"
"uint32 VEHICLE_TRUCK                    = 49    # 0x0031\n"
"uint32 VEHICLE_BUS                      = 65    # 0x0041\n"
"uint32 VEHICLE_SCHOOLBUS                = 321   # 0x0141\n"
"uint32 VEHICLE_SCHOOLBUS_STOP           = 4417  # 0x1141\n"
"uint32 VEHICLE_EMERGENCY                = 81    # 0x0051, emergency vehicles, including \n"
"uint32 VEHICLE_EMERGENCY_POLICE         = 337   # 0x0151\n"
"uint32 VEHICLE_EMERGENCY_POLICE_FLASH   = 4433  # 0x1151\n"
"uint32 VEHICLE_EMERGENCY_FIRE           = 593   # 0x0251\n"
"uint32 VEHICLE_EMERGENCY_FIRE_FLASH     = 4689  # 0x1251\n"
"uint32 VEHICLE_EMERGENCY_CIVIL          = 849   # 0x0351, including utility vehicle and tow trucks\n"
"uint32 VEHICLE_EMERGENCY_CIVIL_FLASH    = 4945  # 0x1351\n"
"\n"
"uint32 HUMAN                            = 2     # 0x0002\n"
"uint32 HUMAN_PEDESTRIAN                 = 18    # 0x0012\n"
"uint32 HUMAN_ROADWORKER                 = 34    # 0x0022\n"
"\n"
"uint32 CYCLIST                          = 3     # 0x0003\n"
"uint32 CYCLIST_BICYCLE                  = 19    # 0x0013\n"
"uint32 CYCLIST_MOTORCYCLE               = 35    # 0x0023\n"
"uint32 CYCLIST_TRICYCLE                 = 51    # 0x0033\n"
"\n"
"uint32 ANIMAL                           = 4     # 0x0004\n"
"uint32 ANIMAL_DOGLIKE                   = 20    # 0x0014, includes dog, cat, wolf, etc.\n"
"uint32 ANIMAL_DEERLIKE                  = 36    # 0x0024, includes deer, etc.\n"
"uint32 ANIMAL_COWLIKE                   = 52    # 0x0034, includes cow, horse, pig, etc.\n"
"\n"
"uint32 ROAD_OBJECT                      = 5     # 0x0005, objects in road area\n"
"uint32 ROAD_TRAFFIC_CONE                = 21    # 0x0015, traffic cone\n"
"uint32 ROAD_TRAFFIC_BLOCKER             = 37    # 0x0025, traffic blocker, e.g. \"Road Closed\" sign\n"
"\n"
"uint32 ROADSIDE_OBJECT                  = 6     # 0x0006, objects in road side\n"
"uint32 ROADSIDE_TRAFFIC_LIGHT           = 22    # 0x0016\n"
"uint32 ROADSIDE_TRAFFIC_SIGN            = 38    # 0x0026\n"
"uint32 ROADSIDE_TREE                    = 54    # 0x0036, including all roadside vegetation\n"
"\n"
"uint32 LEVEL_MASK_0                     = 15    # 0x000f\n"
"uint32 LEVEL_MASK_1                     = 255   # 0x00ff\n"
"uint32 LEVEL_MASK_2                     = 4095  # 0x0fff\n"
"uint32 LEVEL_MASK_3                     = 65535 # 0xffff\n"
"\n"
"================================================================================\n"
"MSG: zzz_perception_msgs/ObjectSignals\n"
"# This message is used to represent detected vehicle light signals or human hand signals\n"
"\n"
"# Signal flags. Multiple signal emission can exists in the same time.\n"
"uint16 flags\n"
"\n"
"uint16 UNKNOWN                          = 0     # 0x00\n"
"uint16 NONE                             = 16    # 0x10\n"
"\n"
"# This field is related to https://en.wikipedia.org/wiki/Automotive_lighting\n"
"uint16 VEHICLE_SIGNAL                   = 1     # 0x01\n"
"uint16 VEHICLE_SIGNAL_LEFT_TURN         = 17    # 0x11\n"
"uint16 VEHICLE_SIGNAL_RIGHT_TURN        = 33    # 0x21\n"
"uint16 VEHICLE_SIGNAL_HAZARD            = 49    # 0x31\n"
"uint16 VEHICLE_SIGNAL_BRAKE             = 65    # 0x41\n"
"uint16 VEHICLE_SIGNAL_REVERSE           = 81    # 0x51\n"
"uint16 VEHICLE_SIGNAL_SPEED_30_LIMIT    = 97    # 0x61\n"
"\n"
"# This field is related to https://en.wikipedia.org/wiki/Traffic_light#Single_aspects\n"
"uint16 TRAFFIC_LIGHT                    = 2     # 0x02\n"
"uint16 TRAFFIC_LIGHT_RED                = 18    # 0x12\n"
"uint16 TRAFFIC_LIGHT_YELLOW             = 34    # 0x22\n"
"uint16 TRAFFIC_LIGHT_GREEN              = 50    # 0x32\n"
"uint16 TRAFFIC_LIGHT_GREEN_LEFT_TURN    = 66    # 0x42\n"
"uint16 TRAFFIC_LIGHT_GREEN_RIGHT_TURN   = 66    # 0x42\n"
"\n"
"# Confidence of the signal detection\n"
"float32 score\n"
"\n"
"================================================================================\n"
"MSG: zzz_perception_msgs/BoundingBox\n"
"\n"
"# A 3D bounding box that can be positioned and rotated about its center (6 DOF). Dimensions of this box are in meters\n"
"\n"
"# The position and orientation of the rigid body center\n"
"geometry_msgs/PoseWithCovariance pose\n"
"\n"
"# The size of (in meters) the bounding box surrounding the object's center pose.\n"
"DimensionWithCovariance dimension\n"
"================================================================================\n"
"MSG: geometry_msgs/PoseWithCovariance\n"
"# This represents a pose in free space with uncertainty.\n"
"\n"
"Pose pose\n"
"\n"
"# Row-major representation of the 6x6 covariance matrix\n"
"# The orientation parameters use a fixed-axis representation.\n"
"# In order, the parameters are:\n"
"# (x, y, z, rotation about X axis, rotation about Y axis, rotation about Z axis)\n"
"float64[36] covariance\n"
"\n"
"================================================================================\n"
"MSG: geometry_msgs/Pose\n"
"# A representation of pose in free space, composed of position and orientation. \n"
"Point position\n"
"Quaternion orientation\n"
"\n"
"================================================================================\n"
"MSG: geometry_msgs/Point\n"
"# This contains the position of a point in free space\n"
"float64 x\n"
"float64 y\n"
"float64 z\n"
"\n"
"================================================================================\n"
"MSG: geometry_msgs/Quaternion\n"
"# This represents an orientation in free space in quaternion form.\n"
"\n"
"float64 x\n"
"float64 y\n"
"float64 z\n"
"float64 w\n"
"\n"
"================================================================================\n"
"MSG: zzz_perception_msgs/DimensionWithCovariance\n"
"# Describing the size object in 3D space (in meters) with uncertainty\n"
"\n"
"float64 length_x # length(longitudinal direction)\n"
"float64 length_y # width(lateral direction)\n"
"float64 length_z # height\n"
"\n"
"# Row-major representation of the 3x3 covariance matrix\n"
"# In order, the parameters are: (length_x, length_y, length_z)\n"
"float64[9] covariance\n"
;
  }

  static const char* value(const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator>&) { return value(); }
};

} // namespace message_traits
} // namespace ros

namespace ros
{
namespace serialization
{

  template<class ContainerAllocator> struct Serializer< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
  {
    template<typename Stream, typename T> inline static void allInOne(Stream& stream, T m)
    {
      stream.next(m.source_cloud);
      stream.next(m.source_img);
      stream.next(m.source_frame);
      stream.next(m.classes);
      stream.next(m.signal);
      stream.next(m.bbox);
      stream.next(m.comments);
    }

    ROS_DECLARE_ALLINONE_SERIALIZER
  }; // struct DetectionBox_

} // namespace serialization
} // namespace ros

namespace ros
{
namespace message_operations
{

template<class ContainerAllocator>
struct Printer< ::zzz_perception_msgs::DetectionBox_<ContainerAllocator> >
{
  template<typename Stream> static void stream(Stream& s, const std::string& indent, const ::zzz_perception_msgs::DetectionBox_<ContainerAllocator>& v)
  {
    s << indent << "source_cloud: ";
    s << std::endl;
    Printer< ::sensor_msgs::PointCloud2_<ContainerAllocator> >::stream(s, indent + "  ", v.source_cloud);
    s << indent << "source_img: ";
    s << std::endl;
    Printer< ::sensor_msgs::Image_<ContainerAllocator> >::stream(s, indent + "  ", v.source_img);
    s << indent << "source_frame: ";
    Printer<std::basic_string<char, std::char_traits<char>, typename ContainerAllocator::template rebind<char>::other > >::stream(s, indent + "  ", v.source_frame);
    s << indent << "classes[]" << std::endl;
    for (size_t i = 0; i < v.classes.size(); ++i)
    {
      s << indent << "  classes[" << i << "]: ";
      s << std::endl;
      s << indent;
      Printer< ::zzz_perception_msgs::ObjectClass_<ContainerAllocator> >::stream(s, indent + "    ", v.classes[i]);
    }
    s << indent << "signal: ";
    s << std::endl;
    Printer< ::zzz_perception_msgs::ObjectSignals_<ContainerAllocator> >::stream(s, indent + "  ", v.signal);
    s << indent << "bbox: ";
    s << std::endl;
    Printer< ::zzz_perception_msgs::BoundingBox_<ContainerAllocator> >::stream(s, indent + "  ", v.bbox);
    s << indent << "comments: ";
    Printer<std::basic_string<char, std::char_traits<char>, typename ContainerAllocator::template rebind<char>::other > >::stream(s, indent + "  ", v.comments);
  }
};

} // namespace message_operations
} // namespace ros

#endif // ZZZ_PERCEPTION_MSGS_MESSAGE_DETECTIONBOX_H
